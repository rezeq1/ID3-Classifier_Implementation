{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build the model\n",
      "testting the model\n",
      "Number of wrongs:1491  From Total:3031\n",
      "Accuracy:50.81%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log2\n",
    "\n",
    "\n",
    "def read_structure(FileName):\n",
    "    struct = pd.read_csv(FileName, sep=' ', names=['type', 'feature', 'data'])\n",
    "    values = {}\n",
    "    for i in range(0, struct.shape[0]):\n",
    "        row = struct.iloc[i].tolist()\n",
    "        x = (row[2].split(','))\n",
    "        values[row[1]] = set([i.replace('}', '').replace('{', '') for i in x]) if len(x) > 1 else x[0]\n",
    "    return values\n",
    "\n",
    "\n",
    "def entropy(data):\n",
    "    sum = 0\n",
    "    if len(data) <= 1:\n",
    "        return 0\n",
    "    temp = {}\n",
    "\n",
    "    for i in data:\n",
    "        if i in temp:\n",
    "            temp[i] += 1\n",
    "        else:\n",
    "            temp[i] = 1\n",
    "    for key in temp:\n",
    "        p = temp[key] / len(data)\n",
    "        sum += p * log2(p)\n",
    "    return -1 * sum\n",
    "\n",
    "\n",
    "def InfoGain(data, attr):\n",
    "    total_entropy = entropy(data[\"class\"])\n",
    "    values, counts = np.unique(data[attr], return_counts=True)\n",
    "    weightes = []\n",
    "    for i in range(0, len(values)):\n",
    "        weightes.append((counts[i] / sum(counts)) * entropy(data[data[attr] == values[i]]['class'].tolist()))\n",
    "    return total_entropy - sum(weightes)\n",
    "\n",
    "\n",
    "def Get_Decision_Tree(data, columns):\n",
    "    # Recursion stop conditions\n",
    "    if len(columns) == 0:\n",
    "        return np.unique(data['class'])[np.argmax(np.unique(data['class'], return_counts=True)[1])]\n",
    "\n",
    "    if len(np.unique(data['class'])) == 1:\n",
    "        return np.unique(data['class'])[0]\n",
    "\n",
    "\n",
    "    # finding the biggest feature's info gain\n",
    "    temp = {}\n",
    "    for i in columns:\n",
    "        temp[i] = InfoGain(data, i)\n",
    "    max_info = max(temp, key=temp.get)\n",
    "\n",
    "    # removing the biggest feature's info gain from the features list\n",
    "    new_col = []\n",
    "    for i in columns:\n",
    "        if i != max_info:\n",
    "            new_col.append(i)\n",
    "\n",
    "    # Recursion to the sup trees untill arrive to leafs\n",
    "    temp = {}\n",
    "    for value in set(data[max_info]):\n",
    "        temp[value] = Get_Decision_Tree(data[data[max_info] == value], new_col)\n",
    "\n",
    "    return {max_info: temp}\n",
    "\n",
    "\n",
    "def Classification_Row(tree, row, columns):\n",
    "\n",
    "    root = list(tree.keys())[0]\n",
    "    result = row[columns.index(root)]\n",
    "    classification = None\n",
    "    if type(result) != str:\n",
    "        for intervl in tree[root]:\n",
    "            if result in intervl:\n",
    "                classification = tree[root][intervl]\n",
    "                break\n",
    "\n",
    "\n",
    "    else:\n",
    "        if result in tree[root]:\n",
    "            classification = tree[root][result]\n",
    "\n",
    "\n",
    "\n",
    "    if type(classification) != dict:\n",
    "        return classification\n",
    "    else:\n",
    "        return Classification_Row(classification,row,columns)\n",
    "\n",
    "\n",
    "def ID3(Test_File,Train_File,Structure_File,NumOfBins):\n",
    "    # Load files\n",
    "    test = pd.read_csv(Test_File)\n",
    "    train = pd.read_csv(Train_File)\n",
    "    struct = read_structure(Structure_File)\n",
    "\n",
    "    # get the rows and the columns of test file\n",
    "    columns = test.columns.tolist()\n",
    "    rows = []\n",
    "    for i in range(0, test.shape[0]):\n",
    "        rows.append(test.iloc[i].tolist())\n",
    "\n",
    "    # fill nan values\n",
    "    nan_columns = train.columns[train.isna().any()].tolist()\n",
    "    for col in nan_columns:\n",
    "        train[col] = train[col].fillna(method='ffill')\n",
    "\n",
    "    nan_columns = test.columns[test.isna().any()].tolist()\n",
    "    for col in nan_columns:\n",
    "        test[col] = test[col].fillna(method='ffill')\n",
    "\n",
    "    # Discretization\n",
    "    for col in columns:\n",
    "        if struct[col] == 'NUMERIC':\n",
    "            train[col] = pd.qcut(train[col], NumOfBins, duplicates='drop')\n",
    "    print('build the model')\n",
    "    # build the model\n",
    "    columns.remove('class')\n",
    "    tree = Get_Decision_Tree(train, columns)\n",
    "    print('testting the model')\n",
    "    # testting the model\n",
    "    columns.append('class')\n",
    "    wrongs = 0\n",
    "    for row in rows:\n",
    "        result = Classification_Row(tree, row, columns)\n",
    "        if result != row[-1]:\n",
    "            wrongs += 1\n",
    "\n",
    "    # showing info\n",
    "    print(\"Number of wrongs:{0}  From Total:{1}\".format(wrongs, len(rows)))\n",
    "    print(\"Accuracy:{:.2f}%\".format(float((len(rows) - wrongs) / len(rows) * 100)))\n",
    "\n",
    "\n",
    "\n",
    "ID3('test.csv','train.csv','Structure.txt',2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
